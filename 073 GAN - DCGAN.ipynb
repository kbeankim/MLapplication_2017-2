{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) [local-paper](http://localhost:8888/notebooks/Dropbox/Paper/1511.06434.pdf) [code-Newmu](https://github.com/Newmu/dcgan_code) [code-carpedm20](https://github.com/carpedm20/DCGAN-tensorflow) [code-nalsil](https://github.com/nalsil/dcgan-completion.tensorflow) [Improved DCGAN](https://arxiv.org/pdf/1606.03498.pdf) [local-paper](http://localhost:8888/notebooks/Dropbox/Paper/1606.03498.pdf)\n",
    "\n",
    "<img src=\"img/DCGAN2.png\"/>\n",
    "\n",
    "<img src=\"img/DCGAN3.png\"/>\n",
    "\n",
    "<img src=\"img/DCGAN4.png\"/>\n",
    "\n",
    "<ul>\n",
    "  <li>Batch normalization is a must in both networks.</li>\n",
    "  <li>Fully hidden connected layers are not a good idea.</li>\n",
    "  <li>Avoid pooling, simply stride your convolutions!</li>\n",
    "  <li>Use LeakyReLU instead of ReLU.</li>\n",
    "  <li>Use Adam optimizer ( lr = 0.0002, a = 0.9, b=0.5 ).</li>\n",
    "</ul>\n",
    "\n",
    "초짜 대학원생의 입장에서 이해하는 DCGAN \n",
    "[1](http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html)\n",
    "[2](http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-2.html)\n",
    "\n",
    "Generative Adversarial Networks Explained with a Classic Spongebob Squarepants Episode [Arthur Juliani](https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39)\n",
    "\n",
    "<img src=\"img/What can GAN do 1.png\"/>\n",
    "\n",
    "<img src=\"img/What can GAN do 2.png\"/>\n",
    "\n",
    "<img src=\"img/What can GAN do 3.png\"/>\n",
    "\n",
    "[A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf) [local-paper](http://localhost:8888/notebooks/Dropbox/Paper/1603-07285.pdf)\n",
    "\n",
    "Generative Adversarial Networks [Hossein Azizpour](https://www.kth.se/social/files/59086d09f2765460c378ca73/GANs.pdf) [local-paper](http://localhost:8888/notebooks/Dropbox/Paper/GANs - Hossein Azizpour.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Number of train samples: 55000, Shape of y: (55000, 10), Shape of X: (55000, 784)\n",
      "0.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122b1a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f51b58fcc3bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# The below code is responsible for applying gradient descent to update the GAN.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mtrainerD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0mtrainerG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0md_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainerD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Only update the weights for the discriminator network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'a'"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/awjuliani/8ebf356d03ffee139659807be7fa2611#file-dcgan-ipynb\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import scipy.misc\n",
    "import scipy\n",
    "\n",
    "z_size = 100 # Size of z vector used for generator.\n",
    "batch_size = 128 # Size of image batch to apply at each iteration.\n",
    "batch_size_sample = 36\n",
    "iterations = 500000 # Total number of iterations to use.\n",
    "sample_directory = './figs' # Directory to save sample images from generator in.\n",
    "model_directory = './models' # Directory to save trained model to.\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    mnist = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)\n",
    "except:\n",
    "    mnist = input_data.read_data_sets('../../Data/MNIST', one_hot=True)\n",
    "    \n",
    "n_samples = mnist.train.num_examples\n",
    "X_dim = mnist.train.images.shape[1] # 28 * 28 = 784\n",
    "y_dim = mnist.train.labels.shape[1] # 10\n",
    "print(\"Number of train samples: {}, Shape of y: {}, Shape of X: {}\"\n",
    "      .format(mnist.train.num_examples, mnist.train.labels.shape, mnist.train.images.shape))\n",
    "print(mnist.train.images.min())\n",
    "print(mnist.train.images.max())\n",
    "plt.imshow(np.reshape(-mnist.train.images[4242], (28, 28)), interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "# Helper Functions - This function performns a leaky relu activation, which is needed for the discriminator network.\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "     with tf.variable_scope(name):\n",
    "            f1 = 0.5 * (1 + leak)\n",
    "            f2 = 0.5 * (1 - leak)\n",
    "            return f1 * x + f2 * abs(x)\n",
    "    \n",
    "# Helper Functions - The below functions are taken from carpdem20's implementation https://github.com/carpedm20/DCGAN-tensorflow\n",
    "# They allow for saving sample images from the generator to follow progress\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "    return img\n",
    "\n",
    "# Defining the Adversarial Networks - Generator Network\n",
    "def generator(z):\n",
    "    \n",
    "    zP = slim.fully_connected(z,4*4*256,normalizer_fn=slim.batch_norm,\n",
    "        activation_fn=None,scope='g_project',weights_initializer=initializer)\n",
    "    zCon = tf.reshape(zP,[-1,4,4,256])\n",
    "    \n",
    "    # tf.nn.conv2d_transpose(value, filter, output_shape, strides, padding, name)\n",
    "    gen1 = slim.convolution2d_transpose(\n",
    "        zCon,num_outputs=64,kernel_size=[5,5],stride=[2,2],\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\n",
    "        activation_fn=tf.nn.relu,scope='g_conv1', weights_initializer=initializer)\n",
    "    \n",
    "    gen2 = slim.convolution2d_transpose(\n",
    "        gen1,num_outputs=32,kernel_size=[5,5],stride=[2,2],\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\n",
    "        activation_fn=tf.nn.relu,scope='g_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    g_out = slim.convolution2d_transpose(\n",
    "        gen2,num_outputs=1,kernel_size=[5,5],stride=[2,2],\n",
    "        padding=\"SAME\",\n",
    "        activation_fn=tf.nn.sigmoid,scope='g_conv3', weights_initializer=initializer)\n",
    "    \n",
    "    return g_out\n",
    "\n",
    "# Defining the Adversarial Networks - Discriminator Network\n",
    "def discriminator(bottom, reuse=False):\n",
    "    \n",
    "    dis1 = slim.convolution2d(bottom,16,[4,4],stride=[2,2],padding=\"SAME\",\n",
    "        biases_initializer=None,activation_fn=lrelu,\n",
    "        reuse=reuse,scope='d_conv1',weights_initializer=initializer)\n",
    "    \n",
    "    dis2 = slim.convolution2d(dis1,32,[4,4],stride=[2,2],padding=\"SAME\",\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\n",
    "        reuse=reuse,scope='d_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    dis3 = slim.convolution2d(dis2,64,[4,4],stride=[2,2],padding=\"SAME\",\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\n",
    "        reuse=reuse,scope='d_conv3',weights_initializer=initializer)\n",
    "    \n",
    "    d_out = slim.fully_connected(slim.flatten(dis3),1,activation_fn=tf.nn.sigmoid,\n",
    "        reuse=reuse,scope='d_out', weights_initializer=initializer)\n",
    "    \n",
    "    return d_out\n",
    "\n",
    "# Defining the Adversarial Networks - Connecting them together\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# This initializaer is used to initialize all the weights of the network.\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "# These two placeholders are used for input into the generator and discriminator, respectively.\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "real_in = tf.placeholder(shape=[None,32,32,1],dtype=tf.float32) #Real images\n",
    "\n",
    "Gz = generator(z_in) #Generates images from random z vectors\n",
    "Dx = discriminator(real_in) #Produces probabilities for real images\n",
    "Dg = discriminator(Gz,reuse=True) #Produces probabilities for generator images\n",
    "\n",
    "# These functions together define the optimization objective of the GAN.\n",
    "d_loss = - tf.reduce_mean(tf.log(Dx)) - tf.reduce_mean(tf.log(1.-Dg)) #This optimizes the discriminator.\n",
    "g_loss =                              - tf.reduce_mean(tf.log(Dg)) #This optimizes the generator.\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "# The below code is responsible for applying gradient descent to update the GAN.\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "trainerG = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "d_grads = trainerD.compute_gradients(d_loss,tvars[9:]) #Only update the weights for the discriminator network.\n",
    "g_grads = trainerG.compute_gradients(g_loss,tvars[0:9]) #Only update the weights for the generator network.\n",
    "\n",
    "update_D = trainerD.apply_gradients(d_grads)\n",
    "update_G = trainerG.apply_gradients(g_grads)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate a random z batch\n",
    "        xs,_ = mnist.train.next_batch(batch_size) #Draw a sample batch from MNIST dataset.\n",
    "        xs = (np.reshape(xs,[batch_size,28,28,1]) - 0.5) * 2.0 #Transform it to be between -1 and 1\n",
    "        # https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.pad.html\n",
    "        xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1)) #Pad the images so the are 32x32\n",
    "        _,dLoss = sess.run([update_D,d_loss],feed_dict={z_in:zs,real_in:xs}) #Update the discriminator\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs}) #Update the generator, twice for good measure.\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs})\n",
    "        if i % 10 == 0:\n",
    "            print(\"Gen Loss: \" + str(gLoss) + \" Disc Loss: \" + str(dLoss))\n",
    "            z2 = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate another z batch\n",
    "            newZ = sess.run(Gz,feed_dict={z_in:z2}) #Use new z to get sample images from generator.\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_images(np.reshape(newZ[0:36],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "            print(\"Saved Model\")\n",
    "            \n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    #Reload the model.\n",
    "    print('Loading Model...')\n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    \n",
    "    zs = np.random.uniform(-1.0,1.0,size=[batch_size_sample,z_size]).astype(np.float32) #Generate a random z batch\n",
    "    newZ = sess.run(Gz,feed_dict={z_in:z2}) # Use new z to get sample images from generator.\n",
    "    if not os.path.exists(sample_directory):\n",
    "        os.makedirs(sample_directory)\n",
    "    save_images(np.reshape(newZ[0:batch_size_sample],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
